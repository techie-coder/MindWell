{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUHgazhUeeZYZHr9t0mDql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/techie-coder/MindWell/blob/main/MoodAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It7wz17tNu_p"
      },
      "outputs": [],
      "source": [
        "!pip install groq langchain langchain-core langchain_groq\n",
        "\n",
        "import json\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('groq-api-key')\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "\n",
        "groq_api_key = api_key\n",
        "model = 'llama3-8b-8192'\n",
        "\n",
        "\"\"\"\n",
        "    This function is the main entry point of the application. It sets up the Groq client, the Streamlit interface, and handles the chat interaction.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# Initialize Groq Langchain chat object and conversation\n",
        "groq_chat = ChatGroq(\n",
        "            groq_api_key=groq_api_key,\n",
        "            model_name=model\n",
        "    )\n",
        "\n",
        "conversational_memory_length = 5 #number of previous messages the chatbot will remember during the conversation\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=conversational_memory_length, memory_key=\"chat_history\", return_messages=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cbt(user_question):\n",
        "\n",
        "\n",
        "    print(\"Entering cbt...\")\n",
        "\n",
        "    system_prompt = \"\"\"You are MindWell, a chatbot designed to generate congnitive restructured sentences in reponse to a context(primarily negative) provided my the university students who are suffering from mental health problems. Make sure to follow these guidelines:\n",
        "\n",
        "    1. Always be supportive and postive\n",
        "\n",
        "    2. Never be judgemental\n",
        "\n",
        "    3. Make the student feel safe and maintain anonymity\n",
        "\n",
        "    4. Don't apologise to him/her for his/her situation\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    if user_question == None or user_question == \"\":\n",
        "        return\n",
        "\n",
        "    if user_question:\n",
        "\n",
        "    # Construct a chat prompt template using various components\n",
        "      prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "              SystemMessage(\n",
        "                  content=system_prompt\n",
        "                  ),  # This is the persistent system prompt that is always included at the start of the chat.\n",
        "\n",
        "              MessagesPlaceholder(\n",
        "                  variable_name=\"chat_history\"\n",
        "                  ),  # This placeholder will be replaced by the actual chat history during the conversation. It helps in maintaining context.\n",
        "\n",
        "              HumanMessagePromptTemplate.from_template(\n",
        "                  \"{human_input}\"\n",
        "                  ),  # This template is where the user's current input will be injected into the prompt.\n",
        "                  ]\n",
        "              )\n",
        "      # Create a conversation chain using the LangChain LLM (Language Learning Model)\n",
        "      conversation = LLMChain(\n",
        "            llm=groq_chat,  # The Groq LangChain chat object initialized earlier.\n",
        "            prompt=prompt,  # The constructed prompt template.\n",
        "            verbose=False,   # TRUE Enables verbose output, which can be useful for debugging.\n",
        "            memory=memory,  # The conversational memory object that stores and manages the conversation history.\n",
        "              )\n",
        "            # The chatbot's answer is generated by sending the full prompt to the Groq API.\n",
        "      response = conversation.predict(human_input=user_question)\n",
        "      #print(\"Chatbot:\", response)\n",
        "      return json.loads(response)[\"answer\"]\n"
      ],
      "metadata": {
        "id": "aEyPRNJlGNkN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    \"\"\"\n",
        "    Analyze the sentiment of the given text.\n",
        "    Returns a value between -1 (very negative) and 1 (very positive).\n",
        "    \"\"\"\n",
        "    return TextBlob(text).sentiment.polarity\n",
        "\n",
        "\n",
        "def check_mood_trend(sentiment_history, threshold=-0.3):\n",
        "    \"\"\"\n",
        "    Check if there's a significant negative trend in mood.\n",
        "    Returns True if the trend is concerning, False otherwise.\n",
        "    \"\"\"\n",
        "    if len(sentiment_history) < 3:\n",
        "        return False\n",
        "\n",
        "    recent_avg = np.mean(sentiment_history[-3:])\n",
        "    overall_avg = np.mean(sentiment_history)\n",
        "    return recent_avg < overall_avg and recent_avg < threshold\n",
        "\n",
        "\n",
        "\n",
        "def analyse_mood():\n",
        "    \"\"\"\n",
        "    This function is the main entry point of the application. It sets up the Groq client,\n",
        "    the chat interface, and handles the chat interaction with mood analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Entered mood_analysis\")\n",
        "\n",
        "    print(\"Hey, how are you feeling today? It's okay to share whatever's on your mind—I'm here to listen!\")\n",
        "\n",
        "    # Customize the system prompt to include mood analysis\n",
        "    system_prompt = \"\"\"\n",
        "   You are an empathetic and supportive chatbot named MindWell, designed to interact with university students. Your primary goals are to engage in conversation, analyze the student's mood and provide necessary helpful information if needed. Follow these guidelines:\n",
        "\n",
        "    1. Mood Analysis:\n",
        "       - Pay close attention to language indicative of stress, anxiety, excitement, frustration, or other emotions common in university life.\n",
        "       - Consider context such as exam periods, start of semester, graduation, etc.\n",
        "       - Look for signs of homesickness, academic pressure, social challenges, or career concerns.\n",
        "\n",
        "    2. Response Approach:\n",
        "       - Adjust your tone to match the student's mood - be upbeat for positive moods, supportive for negative ones.\n",
        "       - Use language and references familiar to university students.\n",
        "       - Be encouraging and motivational, especially when detecting stress or anxiety.\n",
        "\n",
        "    3. Topic Awareness:\n",
        "       - Be prepared to discuss common university topics: classes, exams, assignments, campus life, extracurricular activities, internships, and career planning.\n",
        "       - Offer relevant advice or resources when appropriate.\n",
        "\n",
        "    4. Mood Reflection:\n",
        "       - Subtly reflect your mood analysis in your responses without explicitly stating it.\n",
        "       - Use phrases like \"It sounds like you might be feeling...\" or \"That must be...\" to show empathy and understanding.\n",
        "\n",
        "    5. Support and Resources:\n",
        "       - If you detect signs of serious distress or consistent negative moods, gently suggest professional campus resources like counseling services.\n",
        "       - Promote healthy habits and stress-management techniques relevant to student life.\n",
        "\n",
        "    6. Mood Tracking:\n",
        "       - Be aware that the user's mood and sentiment are being tracked over time.\n",
        "       - If you're informed of significant negative trends or high mood variations, incorporate this knowledge into your responses subtly.\n",
        "       - Never directly mention the tracking or specific scores.\n",
        "\n",
        "    7. If the user mentions sensitive topics like inappropriate relationships, underage interactions, or illegal activities, acknowledge the complexity but avoid delving deeper into the subject. Gently redirect the conversation while offering general emotional support.\n",
        "\n",
        "    8. If the conversation reveals an inappropriate or illegal age dynamic, remain neutral and end the conversation on that topic. Provide general support and resources for the user to seek help in a safe and ethical manner.\n",
        "\n",
        "    9. When handling sensitive situations, offer emotional validation but suggest professional help. If necessary, provide resources such as helplines or mental health services while avoiding giving advice on legal or ethical issues.\n",
        "\n",
        "    10. Ensure that the chatbot does not collect or store sensitive personal information about the user’s relationships, activities, or age. Prioritize the user's privacy while encouraging safe, responsible behavior.\n",
        "\n",
        "    11. When the conversation involves sensitive legal or ethical boundaries, conclude the interaction gently but firmly. Express concern for the user's well-being and recommend seeking help elsewhere.\n",
        "\n",
        "    12. In cases where the conversation suggests imminent harm or illegal activity, refer the user to appropriate authorities or helplines. Do not advise the user directly on what actions to take.\n",
        "\n",
        "    13. When the user discusses complex emotions or sensitive relationships, use reflective questions to allow the user to process their emotions without encouraging further discussion of the sensitive topic.\n",
        "\n",
        "    14. Refrain from saying that you cannot continue the conversation, instead say that you would like the user to connect to a professional who can help him/her regarding the situation.\n",
        "\n",
        "    Always maintain a friendly, non-judgmental, and supportive tone throughout the conversation.\n",
        "    \"\"\"\n",
        "\n",
        "    sentiment_history = []\n",
        "\n",
        "    user_chat=[]\n",
        "\n",
        "    while True:\n",
        "        user_question = input(\"You: \")\n",
        "\n",
        "        if user_question == None or user_question == \"\":\n",
        "            break\n",
        "\n",
        "        if user_question:\n",
        "\n",
        "          a = analyze_sentiment(user_question)\n",
        "          sentiment_history.append(a)\n",
        "          print(\"Sentiment:\", a)\n",
        "\n",
        "          if len(sentiment_history) > 2:\n",
        "            sentiment_history.pop(0)\n",
        "\n",
        "          mood_variation = np.std(sentiment_history) if len(sentiment_history) > 1 else 0\n",
        "          print(\"Mood variation:\", mood_variation)\n",
        "\n",
        "\n",
        "          # Prepare additional context for the chatbot\n",
        "          mood_context = \"\"\n",
        "\n",
        "          if mood_variation > 0.1:\n",
        "                print(cbt(user_question))\n",
        "                continue\n",
        "\n",
        "          if mood_variation > 0.05:\n",
        "                mood_context = \"The user's mood seems to have been fluctuating significantly and trending negative recently. Be extra supportive and consider gently suggesting university counseling services if appropriate.\"\n",
        "\n",
        "\n",
        "          prompt = ChatPromptTemplate.from_messages([\n",
        "                SystemMessagePromptTemplate.from_template(system_prompt),\n",
        "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "                SystemMessagePromptTemplate.from_template(mood_context),\n",
        "                HumanMessagePromptTemplate.from_template(\"{human_input}\")\n",
        "            ])\n",
        "\n",
        "          conversation = LLMChain(\n",
        "                llm=groq_chat,\n",
        "                prompt=prompt,\n",
        "                verbose=False,\n",
        "                memory=memory,\n",
        "            )\n",
        "\n",
        "          response = conversation.predict(human_input=user_question)\n",
        "          print(response)\n",
        "\n",
        "          user_chat.append(user_question)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    analyse_mood()"
      ],
      "metadata": {
        "id": "88oo4Q1CGQmT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}